{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import librariess & define nnApproximation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class created\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\") # GPU에서 실행하려면 이 주석을 제거하세요\n",
    "\n",
    "class nnApproximation(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(nnApproximation, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim+1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "print(\"class created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparameters & Samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "num_epochs = 1000\n",
    "num_samples = 100\n",
    "test_samples = 1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "m4=nnApproximation(4)\n",
    "m8=nnApproximation(8)\n",
    "m16=nnApproximation(16)\n",
    "m32=nnApproximation(32)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "\n",
    "op4 = torch.optim.Adam(m4.parameters(), lr=learning_rate)\n",
    "op8 = torch.optim.Adam(m8.parameters(), lr=learning_rate)\n",
    "op16 = torch.optim.Adam(m16.parameters(), lr=learning_rate)\n",
    "op32 = torch.optim.Adam(m32.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"model created\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training(generate random inputs per epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training model with 4 params\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\cloudservices\\dropbox\\dropbox\\2023-1-lastchance\\pgm\\prj\\pretrain\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Training loop for param4\n",
    "print(\"starting training model with 4 params\")\n",
    "loss4list=list()\n",
    "for epoch in range(num_epochs):\n",
    "    # Generate random input\n",
    "    X = torch.rand(num_samples, 4).to(device)*10\n",
    "    current_loss = 0.0\n",
    "    for t in range(num_samples):\n",
    "        Xs=X[t]\n",
    "        op4.zero_grad()\n",
    "        pred=m4(Xs)\n",
    "        if torch.isnan(pred).any():\n",
    "            print(\"nan detected\")\n",
    "        log_sum = torch.log(torch.sum(Xs))\n",
    "        log_individual = torch.sum(torch.log(Xs) * pred[:-1])\n",
    "        log_constant = pred[-1]\n",
    "        loss = loss_function(torch.pow(torch.abs(log_sum - log_individual - log_constant), 2), torch.zeros(4))\n",
    "        loss.backward()\n",
    "        op4.step()\n",
    "        current_loss += loss.item()\n",
    "        if t % 10 == 0:\n",
    "            #print('Loss after mini-batch %5d: %.3f' %\n",
    "            #      (t + 1, current_loss / 500))\n",
    "            loss4list.append(current_loss)\n",
    "            current_loss = 0.0\n",
    "print(len(loss4list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training model with 8 params\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Training loop for param4\n",
    "print(\"starting training model with 8 params\")\n",
    "loss8list=list()\n",
    "for epoch in range(num_epochs):\n",
    "    X = torch.rand(num_samples, 8).to(device)*10\n",
    "    # Generate random input\n",
    "    current_loss = 0.0\n",
    "    for t in range(num_samples):\n",
    "        Xs=X[t]\n",
    "        op8.zero_grad()\n",
    "        pred=m8(Xs)\n",
    "        if torch.isnan(pred).any():\n",
    "            print(\"nan detected\")\n",
    "        log_sum = torch.log(torch.sum(Xs))\n",
    "        log_individual = torch.sum(torch.log(Xs) * pred[:-1])\n",
    "        log_constant = pred[-1]\n",
    "        loss = loss_function(torch.pow(torch.abs(log_sum - log_individual - log_constant), 2), torch.zeros(4))\n",
    "        loss.backward()\n",
    "        op8.step()\n",
    "        current_loss += loss.item()\n",
    "        if t % 10 == 0:\n",
    "            #print('Loss after mini-batch %5d: %.3f' %\n",
    "            #      (t + 1, current_loss / 500))\n",
    "            loss8list.append(current_loss)\n",
    "            current_loss = 0.0\n",
    "print(len(loss8list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training model with 16 params\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Training loop for param4\n",
    "print(\"starting training model with 16 params\")\n",
    "loss16list=list()\n",
    "for epoch in range(num_epochs):\n",
    "    X = torch.rand(num_samples, 16).to(device)*10\n",
    "    # Generate random input\n",
    "    current_loss = 0.0\n",
    "    for t in range(num_samples):\n",
    "        Xs=X[t]\n",
    "        op16.zero_grad()\n",
    "        pred=m16(Xs)\n",
    "        if torch.isnan(pred).any():\n",
    "            print(\"nan detected\")\n",
    "        log_sum = torch.log(torch.sum(Xs))\n",
    "        log_individual = torch.sum(torch.log(Xs) * pred[:-1])\n",
    "        log_constant = pred[-1]\n",
    "        loss = loss_function(torch.pow(torch.abs(log_sum - log_individual - log_constant), 2), torch.zeros(4))\n",
    "        loss.backward()\n",
    "        op16.step()\n",
    "        current_loss += loss.item()\n",
    "        if t % 10 == 0:\n",
    "            #print('Loss after mini-batch %5d: %.3f' %\n",
    "            #      (t + 1, current_loss / 500))\n",
    "            loss16list.append(current_loss)\n",
    "            current_loss = 0.0\n",
    "print(len(loss16list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training model with 32 params\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Training loop for param4\n",
    "print(\"starting training model with 32 params\")\n",
    "loss32list=list()\n",
    "for epoch in range(num_epochs):\n",
    "    # Generate random input\n",
    "    X = torch.rand(num_samples, 32).to(device)*10\n",
    "    current_loss = 0.0\n",
    "    for t in range(num_samples):\n",
    "        Xs=X[t]\n",
    "        op32.zero_grad()\n",
    "        pred=m32(Xs)\n",
    "        if torch.isnan(pred).any():\n",
    "            print(\"nan detected\")\n",
    "        log_sum = torch.log(torch.sum(Xs))\n",
    "        log_individual = torch.sum(torch.log(Xs) * pred[:-1])\n",
    "        log_constant = pred[-1]\n",
    "        loss = loss_function(torch.pow(torch.abs(log_sum - log_individual - log_constant), 2), torch.zeros(4))\n",
    "        loss.backward()\n",
    "        op32.step()\n",
    "        current_loss += loss.item()\n",
    "        if t % 10 == 0:\n",
    "            #print('Loss after mini-batch %5d: %.3f' %\n",
    "            #      (t + 1, current_loss / 500))\n",
    "            loss32list.append(current_loss)\n",
    "            current_loss = 0.0\n",
    "print(len(loss32list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot data from m4 model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6097, 2.2165, 3.2969, 3.0615, 3.2193, 2.7318, 3.0327, 2.7805, 3.0215,\n",
      "        2.3655, 3.3073, 3.1111, 3.2362, 3.2249, 3.0330, 3.3617, 2.9803, 2.4290,\n",
      "        3.1708, 3.0203, 2.9642, 2.6594, 3.3366, 2.9131, 2.8522, 2.8452, 2.7317,\n",
      "        3.0125, 3.3905, 3.0422, 2.8488, 2.9912, 2.3903, 2.6184, 2.4310, 2.9925,\n",
      "        2.8279, 2.8076, 2.5885, 3.0432, 2.1489, 2.8981, 3.2264, 2.6193, 2.3147,\n",
      "        2.3976, 2.9485, 2.4095, 3.1327, 2.6261, 3.1921, 2.4836, 3.2056, 3.0064,\n",
      "        3.0238, 3.0249, 2.7724, 3.2952, 2.6942, 2.7146, 2.7883, 3.2058, 3.2857,\n",
      "        3.1948, 3.4935, 3.1369, 2.6904, 2.4357, 2.5199, 2.4806, 2.5862, 2.6365,\n",
      "        2.9062, 2.8562, 2.3238, 3.1708, 2.9561, 2.0952, 2.6421, 3.0366, 2.8361,\n",
      "        2.3103, 3.2890, 2.9525, 3.3468, 3.3265, 2.8398, 3.1684, 2.9901, 1.3917,\n",
      "        2.9073, 2.9507, 3.3654, 2.7841, 2.3562, 3.3287, 3.0329, 2.2740, 3.1331,\n",
      "        2.9486, 2.6699, 3.1679, 3.0533, 3.3452, 3.0446, 3.3663, 2.9399, 3.2436,\n",
      "        3.1619, 3.2077, 3.0918, 3.1496, 2.9433, 3.2773, 2.6924, 2.8704, 3.1912,\n",
      "        2.3910, 2.8615, 3.0860, 2.9191, 3.3417, 3.0976, 3.0895, 3.1368, 3.2717,\n",
      "        3.0046, 2.7573, 2.7755, 2.8018, 3.3164, 3.4334, 2.7532, 3.0321, 2.3066,\n",
      "        2.9791, 3.0357, 2.7895, 2.6241, 3.1659, 3.1511, 2.8946, 2.8507, 3.2938,\n",
      "        3.1522, 2.9788, 2.7524, 2.9256, 3.2947, 3.2997, 2.8405, 2.0708, 2.7658,\n",
      "        3.0761, 3.0067, 3.2357, 3.2183, 2.7194, 3.0804, 3.3949, 2.8167, 2.8165,\n",
      "        2.8298, 3.2544, 2.7211, 3.2429, 2.7513, 2.5442, 3.4622, 2.4497, 3.4044,\n",
      "        3.3500, 3.1058, 2.4465, 3.0278, 2.8956, 2.7283, 1.9924, 2.8151, 3.2806,\n",
      "        2.8226, 3.0890, 3.1688, 2.3632, 3.2555, 2.9884, 3.0571, 3.1177, 2.9171,\n",
      "        2.5553, 3.3371, 3.0212, 3.1197, 2.9280, 2.7755, 2.9069, 3.2814, 3.0370,\n",
      "        2.9500, 2.8550, 3.2322, 2.9658, 3.1192, 2.8781, 3.0758, 3.2148, 3.2243,\n",
      "        3.1428, 2.7260, 3.0043, 2.3484, 2.7879, 2.8284, 3.2063, 2.8886, 3.2613,\n",
      "        2.9276, 3.5287, 3.1690, 2.9825, 2.6025, 2.8908, 3.4803, 2.9431, 2.5186,\n",
      "        3.2975, 2.9216, 3.3597, 3.2212, 3.1531, 2.9698, 3.2984, 3.2130, 3.1072,\n",
      "        2.9200, 2.5560, 2.9695, 2.7235, 3.2546, 2.8726, 3.1888, 2.0761, 3.1864,\n",
      "        3.0389, 1.9616, 3.3367, 3.0106, 3.3132, 2.9859, 2.9722, 2.6408, 2.4833,\n",
      "        3.1595, 2.4473, 2.4909, 2.6388, 3.2973, 3.1447, 2.4143, 3.0684, 3.1823,\n",
      "        2.8730, 3.2390, 3.0779, 3.1513, 3.3554, 3.2118, 3.1131, 2.9921, 2.7255,\n",
      "        3.2213, 2.8126, 2.6358, 3.4773, 2.6835, 3.2003, 3.2886, 2.5764, 3.1400,\n",
      "        2.5494, 2.8680, 2.1663, 2.7578, 3.1689, 3.1806, 3.2049, 3.3166, 3.1722,\n",
      "        2.5462, 3.0403, 2.3992, 3.2756, 3.2137, 3.0732, 2.6726, 3.0604, 3.1473,\n",
      "        3.4280, 2.5974, 2.9948, 2.9541, 3.3162, 2.5036, 3.1081, 3.0262, 3.3144,\n",
      "        2.8397, 3.0223, 3.1811, 2.2864, 2.9422, 2.9409, 2.8338, 3.2299, 2.2945,\n",
      "        3.2745, 3.3184, 3.4080, 3.2836, 2.7867, 2.6796, 3.1700, 2.9879, 3.4232,\n",
      "        2.5131, 3.1974, 2.2436, 3.2460, 3.3108, 3.1149, 2.8136, 2.5701, 2.7236,\n",
      "        2.9990, 3.2048, 3.1909, 2.0830, 2.8913, 2.7589, 3.1827, 2.8319, 3.0513,\n",
      "        2.8935, 2.8508, 2.9729, 2.9492, 3.3231, 3.3085, 3.3739, 3.2011, 2.7481,\n",
      "        3.1961, 3.1537, 2.9365, 2.0987, 2.1637, 3.2718, 2.4364, 2.6958, 2.9519,\n",
      "        2.8313, 3.2582, 3.1669, 3.1885, 3.1756, 3.1111, 3.0291, 2.9168, 3.0910,\n",
      "        2.4361, 3.2947, 2.8572, 2.3297, 2.5548, 3.2573, 2.4369, 2.8455, 2.3229,\n",
      "        2.9838, 3.3271, 3.3963, 3.1502, 3.2914, 3.1690, 3.1981, 2.9331, 3.0479,\n",
      "        3.0957, 2.9416, 2.9037, 3.1674, 3.0412, 3.0451, 2.8388, 2.7621, 3.3207,\n",
      "        3.3061, 3.2715, 2.8760, 2.3727, 3.0670, 2.9795, 3.0717, 3.0012, 2.8585,\n",
      "        2.9524, 2.9494, 2.8429, 3.0753, 2.8743, 2.0551, 3.3049, 3.0433, 2.4181,\n",
      "        3.0122, 2.8243, 3.4442, 2.8271, 2.8538, 2.7198, 2.9908, 2.9998, 2.4709,\n",
      "        3.3097, 3.3527, 2.9461, 3.4072, 3.0029, 2.8999, 2.9378, 3.0142, 3.0007,\n",
      "        3.3448, 2.9588, 2.7104, 2.9513, 3.2375, 3.3075, 2.4715, 3.2157, 3.2202,\n",
      "        3.1170, 2.6702, 3.1042, 2.8693, 2.3936, 2.5427, 3.5297, 2.9945, 3.2948,\n",
      "        3.3526, 2.7757, 3.2933, 3.1067, 2.9472, 2.4698, 3.0778, 3.2396, 2.3888,\n",
      "        3.0761, 2.2098, 3.0896, 2.8859, 2.1087, 3.2049, 2.5593, 3.0155, 3.4233,\n",
      "        3.0306, 2.9674, 2.7404, 3.3418, 3.1633, 2.0047, 3.2591, 2.9689, 3.1778,\n",
      "        3.3921, 3.0950, 2.5972, 2.7129, 3.3412, 2.8844, 3.0470, 2.3553, 2.8619,\n",
      "        2.9241, 3.4384, 2.7846, 2.4440, 2.8216, 2.8508, 2.9074, 3.1875, 2.9778,\n",
      "        3.0155, 3.4091, 2.9008, 2.8767, 2.9764, 3.2331, 2.8602, 2.8133, 3.0404,\n",
      "        3.5006, 3.2780, 2.6835, 3.1879, 2.6764, 2.9411, 3.0467, 3.3492, 2.8374,\n",
      "        2.5216, 2.4601, 2.6109, 3.3940, 2.6332, 3.3477, 2.7691, 3.1843, 3.4743,\n",
      "        2.9188, 3.3100, 1.5810, 3.1433, 3.1073, 2.4334, 2.0770, 3.2157, 3.0298,\n",
      "        2.9752, 2.9093, 3.0434, 3.2140, 2.6968, 3.0461, 3.2512, 2.9145, 2.1646,\n",
      "        2.6612, 3.1379, 3.0328, 2.8575, 2.5693, 2.5270, 2.8197, 2.9539, 3.3918,\n",
      "        3.1118, 2.4995, 2.8862, 3.2832, 3.1756, 3.1590, 3.2406, 3.2433, 2.9266,\n",
      "        2.9209, 2.9480, 3.1833, 3.2886, 2.9579, 3.1917, 3.2957, 3.1648, 3.0414,\n",
      "        3.3497, 3.1554, 3.0376, 2.8717, 2.3457, 2.1080, 3.3000, 3.2953, 2.7559,\n",
      "        2.8910, 2.9828, 3.5985, 2.9643, 3.4031, 2.6893, 3.2464, 2.8499, 3.2535,\n",
      "        3.1830, 2.9469, 2.8937, 2.9982, 1.4655, 2.6500, 2.4841, 2.4451, 3.0103,\n",
      "        2.6776, 2.8525, 2.8539, 2.8797, 2.2402, 2.9469, 3.2074, 3.0660, 3.2059,\n",
      "        3.1853, 2.9499, 2.8912, 1.9420, 2.5795, 3.4092, 3.2201, 3.2710, 3.1820,\n",
      "        3.3877, 3.1850, 2.7736, 3.0544, 2.5429, 3.0284, 3.1216, 3.0509, 2.7294,\n",
      "        3.3836, 3.1854, 2.9318, 3.1176, 2.5944, 3.0108, 3.0924, 2.6563, 3.4506,\n",
      "        2.7065, 3.1281, 3.1084, 3.2085, 2.3672, 3.1079, 3.2840, 2.9079, 2.9728,\n",
      "        3.1201, 3.4218, 3.2276, 3.3782, 2.8106, 3.3641, 2.3990, 2.8405, 1.8954,\n",
      "        2.7066, 2.6832, 2.1897, 3.2326, 2.6162, 3.0139, 3.2244, 2.6011, 3.2979,\n",
      "        3.1763, 2.7301, 2.2863, 3.1326, 3.4028, 3.1794, 2.4036, 1.8532, 3.3762,\n",
      "        2.5626, 3.3323, 3.0122, 3.4437, 2.8249, 2.8958, 2.8715, 2.5513, 3.0361,\n",
      "        2.8547, 2.9294, 2.3456, 3.1608, 3.1651, 3.2001, 2.6239, 2.4108, 2.8382,\n",
      "        3.0602, 2.8102, 3.0665, 3.1045, 2.5468, 3.1430, 3.2032, 3.3056, 3.2018,\n",
      "        2.5295, 3.1385, 2.7626, 3.4190, 2.4988, 3.0588, 2.8167, 2.9486, 3.1114,\n",
      "        3.0661, 3.5066, 3.1533, 2.6842, 2.4622, 3.0062, 1.8975, 3.1919, 2.8220,\n",
      "        2.5034, 2.8069, 3.0270, 2.8732, 3.0643, 2.6613, 2.9338, 2.5045, 3.1099,\n",
      "        3.0301, 2.6444, 3.2407, 2.7689, 2.8086, 3.1573, 3.2300, 3.3619, 3.2332,\n",
      "        3.0980, 2.6762, 3.0314, 2.8574, 2.7054, 3.3529, 3.3494, 2.7723, 2.8060,\n",
      "        3.2769, 2.9257, 2.8036, 2.9131, 2.7399, 3.2070, 3.1445, 3.3516, 2.9523,\n",
      "        3.0120, 2.7065, 2.8469, 2.9625, 3.0791, 3.2371, 3.0636, 2.9164, 3.0309,\n",
      "        3.0413, 3.1898, 3.0055, 2.7889, 2.7583, 2.9290, 3.1267, 2.9410, 3.1787,\n",
      "        3.2948, 2.8885, 2.3900, 3.0996, 2.6821, 2.3539, 3.2237, 2.8562, 3.2586,\n",
      "        2.9073, 2.8932, 3.1173, 2.8108, 2.8511, 2.4207, 3.1108, 2.9813, 3.2314,\n",
      "        3.1482, 3.1121, 2.7141, 3.2138, 3.0115, 2.7511, 3.0885, 2.8356, 2.4450,\n",
      "        3.4523, 1.9498, 2.9855, 3.1931, 2.6482, 3.1285, 3.0250, 3.2188, 3.2026,\n",
      "        2.8441, 2.7906, 3.0833, 3.2408, 2.9665, 3.0108, 3.1622, 3.1716, 2.8152,\n",
      "        2.7114, 3.2447, 2.5879, 2.3802, 3.2946, 3.0715, 3.0893, 2.4025, 3.0430,\n",
      "        2.7939, 3.1101, 2.9976, 2.9495, 3.2078, 3.2396, 2.8111, 2.8336, 3.4955,\n",
      "        3.2045, 2.9162, 3.0235, 2.6501, 3.2081, 3.2801, 3.1091, 2.5440, 3.1957,\n",
      "        2.0534, 3.0343, 2.1993, 3.1053, 3.0992, 2.9599, 2.9526, 2.7957, 2.7345,\n",
      "        3.0894, 2.9724, 2.8203, 2.6648, 2.9192, 2.8399, 2.2803, 2.4414, 3.2670,\n",
      "        3.2111, 3.1667, 2.9765, 3.0760, 3.3227, 2.9631, 2.9765, 3.3561, 3.2897,\n",
      "        2.9142, 3.3234, 2.7378, 2.8232, 2.8417, 2.9186, 2.6321, 3.2562, 3.1673,\n",
      "        3.3499, 3.3980, 2.8231, 2.9836, 2.1414, 3.1985, 3.1464, 2.6850, 2.6643,\n",
      "        3.0732, 2.8801, 2.9582, 1.4131, 2.7650, 3.2330, 3.1960, 2.9990, 3.0244,\n",
      "        3.1383, 3.1732, 3.4381, 3.0637, 2.7778, 3.2698, 3.0880, 2.6781, 3.1860,\n",
      "        2.9884, 3.0155, 2.2498, 3.3133, 3.0563, 3.3339, 2.8090, 2.5177, 3.3933,\n",
      "        2.7024, 3.0162, 3.0540, 3.2466, 3.2371, 3.1476, 3.3854, 3.2297, 3.3129,\n",
      "        2.5558, 3.2735, 2.7705, 2.8092, 3.0985, 3.3677, 2.7914, 3.0951, 3.3779,\n",
      "        2.1170, 3.1633, 3.1444, 3.0263, 2.3923, 2.9830, 3.0915, 2.9726, 3.0435,\n",
      "        3.1130, 2.7330, 3.2030, 2.8488, 2.5512, 2.5429, 3.1322, 3.0866, 2.7136,\n",
      "        2.8305, 2.7982, 3.1963, 2.5551, 3.3257, 3.5213, 2.7840, 3.0292, 2.9866,\n",
      "        3.1772, 2.2381, 3.2866, 2.8187, 2.9053, 3.2847, 2.4743, 2.9776, 2.7525,\n",
      "        2.9493, 3.1489, 3.0545, 3.0247, 3.2056, 3.4330, 2.5968, 3.0124, 2.8089,\n",
      "        3.1880, 2.8965, 2.8133, 3.3142, 3.0912, 2.5365, 2.7842, 3.2792, 2.4640,\n",
      "        2.3037, 1.8817, 3.3290, 2.7038, 2.3595, 3.0339, 2.8400, 3.2113, 2.9151,\n",
      "        3.1712, 2.7617, 3.0534, 3.0408, 2.9267, 2.3603, 3.2847, 2.7142, 2.7700,\n",
      "        3.0571])\n",
      "tensor([2.5788, 2.1178, 3.3126, 3.1134, 3.2769, 2.7147, 2.9907, 2.7394, 3.0152,\n",
      "        2.3285, 3.2660, 3.1255, 3.1276, 3.1963, 3.1029, 3.3617, 3.0297, 2.4087,\n",
      "        3.1558, 2.9515, 2.9179, 2.6459, 3.3828, 2.9285, 2.7923, 2.8063, 2.7378,\n",
      "        3.0558, 3.3188, 3.0593, 2.8897, 3.0229, 2.2954, 2.6169, 2.3774, 2.9980,\n",
      "        2.7485, 2.8791, 2.5643, 3.0344, 2.1077, 2.9062, 3.2295, 2.5420, 2.2130,\n",
      "        2.4211, 2.9046, 2.4023, 3.1135, 2.6586, 3.2644, 2.4635, 3.1867, 2.9993,\n",
      "        3.0637, 3.0042, 2.7596, 3.1658, 2.6704, 2.7034, 2.7204, 3.2294, 3.1887,\n",
      "        3.1539, 3.3363, 3.2856, 2.6648, 2.4942, 2.5198, 2.4545, 2.5400, 2.5655,\n",
      "        2.9666, 2.8153, 2.3020, 3.1249, 2.9818, 1.9902, 2.6196, 3.0192, 2.9146,\n",
      "        2.2904, 3.3079, 3.0182, 3.3092, 3.2932, 2.8918, 3.1707, 2.9911, 1.3537,\n",
      "        2.9627, 2.9661, 3.3000, 2.7703, 2.2735, 3.2783, 2.9920, 2.1693, 3.0959,\n",
      "        2.9479, 2.7126, 3.1436, 3.0274, 3.3179, 3.0699, 3.3137, 2.9334, 3.1877,\n",
      "        3.2234, 3.1898, 3.0563, 3.0711, 2.8891, 3.2316, 2.6639, 2.9034, 3.1902,\n",
      "        2.4047, 2.8494, 3.0302, 2.8811, 3.2359, 3.0851, 3.1167, 3.1026, 3.3462,\n",
      "        3.0118, 2.6590, 2.7297, 2.7313, 3.2390, 3.3745, 2.7283, 3.0599, 2.3160,\n",
      "        2.9716, 3.0370, 2.7125, 2.6074, 3.1153, 3.1675, 2.8755, 2.8575, 3.2461,\n",
      "        3.0788, 2.9615, 2.6968, 3.1248, 3.2773, 3.2745, 2.8400, 1.9587, 2.8026,\n",
      "        3.1102, 2.9978, 3.1755, 3.1607, 2.6963, 3.0304, 3.3664, 2.8003, 2.8266,\n",
      "        2.7634, 3.1685, 2.7156, 3.1713, 2.7092, 2.5436, 3.3247, 2.4266, 3.3555,\n",
      "        3.3131, 3.1026, 2.4043, 3.0379, 2.9221, 2.7007, 1.9419, 2.8205, 3.2321,\n",
      "        2.7874, 3.0585, 3.1764, 2.2878, 3.2093, 2.9665, 3.0986, 3.0903, 3.0139,\n",
      "        2.5315, 3.2455, 3.0394, 3.0717, 2.9121, 2.7746, 2.9327, 3.1756, 3.0756,\n",
      "        2.9783, 2.9071, 3.2147, 2.9480, 3.1212, 2.8035, 3.0450, 3.1679, 3.2866,\n",
      "        3.1096, 2.7401, 3.0022, 2.3454, 2.7680, 2.7958, 3.1725, 2.8834, 3.2533,\n",
      "        2.8769, 3.4268, 3.2083, 3.0086, 2.5707, 2.8575, 3.3145, 2.9658, 2.5305,\n",
      "        3.1866, 2.9222, 3.2416, 3.1611, 3.1307, 2.9815, 3.1736, 3.1553, 3.0482,\n",
      "        2.9144, 2.5143, 2.9544, 2.6096, 3.2165, 2.9052, 3.1838, 1.9942, 3.1372,\n",
      "        3.0306, 1.8215, 3.2904, 2.9476, 3.2584, 2.9530, 2.9420, 2.6346, 2.5409,\n",
      "        3.1300, 2.4218, 2.4530, 2.6221, 3.2379, 3.1780, 2.2935, 2.9876, 3.1846,\n",
      "        2.8978, 3.1572, 3.0959, 3.0527, 3.3259, 3.1460, 3.0695, 3.0351, 2.7113,\n",
      "        3.2252, 2.7490, 2.6358, 3.4432, 2.7078, 3.1876, 3.2552, 2.5464, 3.1263,\n",
      "        2.5000, 2.8798, 2.0534, 2.7599, 3.1567, 3.1898, 3.1717, 3.2627, 3.1202,\n",
      "        2.5508, 3.0402, 2.4472, 3.2569, 3.2332, 3.0361, 2.6632, 3.0694, 3.1107,\n",
      "        3.3304, 2.5456, 2.9982, 2.9235, 3.2073, 2.4893, 3.0744, 2.9658, 3.2281,\n",
      "        2.9106, 3.0517, 3.1874, 2.2609, 2.9573, 2.9293, 2.8264, 3.0690, 2.2166,\n",
      "        3.2345, 3.2932, 3.3088, 3.2616, 2.7812, 2.6577, 3.2021, 2.9808, 3.3139,\n",
      "        2.5389, 3.1743, 2.1612, 3.1645, 3.2572, 3.0950, 2.7822, 2.5574, 2.7062,\n",
      "        2.9742, 3.1539, 3.1632, 2.1041, 2.8734, 2.7717, 3.1613, 2.8183, 3.0598,\n",
      "        2.8940, 2.8198, 2.9263, 2.9269, 3.1906, 3.3081, 3.2998, 3.1720, 2.7609,\n",
      "        3.1620, 3.0867, 2.9407, 2.0031, 2.1873, 3.1556, 2.3498, 2.6681, 2.9716,\n",
      "        2.8472, 3.2524, 3.1036, 3.1316, 3.1062, 3.1671, 3.0703, 2.8457, 2.9761,\n",
      "        2.4274, 3.2658, 2.8822, 2.2880, 2.5672, 3.2389, 2.4626, 2.8102, 2.2285,\n",
      "        3.0205, 3.2556, 3.3673, 3.0990, 3.2814, 3.1812, 3.1383, 2.9462, 3.0032,\n",
      "        3.1082, 3.0106, 2.9089, 3.1159, 2.9892, 3.0035, 2.8802, 2.7667, 3.2258,\n",
      "        3.2500, 3.2430, 2.8912, 2.2980, 3.0599, 2.9629, 3.0536, 3.0146, 2.8067,\n",
      "        2.9927, 2.9155, 2.8017, 3.0900, 2.8923, 1.9969, 3.2371, 3.0774, 2.5252,\n",
      "        2.9416, 2.7507, 3.3593, 2.7869, 2.9055, 2.7012, 3.0017, 3.0134, 2.4462,\n",
      "        3.2217, 3.2410, 2.9350, 3.3448, 2.9221, 2.9133, 2.9102, 3.0290, 2.9747,\n",
      "        3.3462, 3.0233, 2.6979, 2.8853, 3.1990, 3.2972, 2.5211, 3.1607, 3.2408,\n",
      "        3.0647, 2.6489, 3.1146, 2.8347, 2.3249, 2.4742, 3.4622, 2.9788, 3.2507,\n",
      "        3.3221, 2.7013, 3.2376, 3.0340, 2.9384, 2.4694, 3.0166, 3.1606, 2.3469,\n",
      "        3.0786, 2.1641, 2.9938, 2.8402, 1.9558, 3.0990, 2.4971, 3.0307, 3.3745,\n",
      "        3.0398, 2.9826, 2.6724, 3.3592, 3.2194, 1.8717, 3.1417, 2.9618, 3.1813,\n",
      "        3.3416, 3.0673, 2.6385, 2.7086, 3.3515, 2.9480, 3.0030, 2.3588, 2.8621,\n",
      "        2.9031, 3.3988, 2.7484, 2.4065, 2.8021, 2.8978, 2.8989, 3.2496, 3.0288,\n",
      "        2.9602, 3.3915, 2.9788, 2.8487, 2.9615, 3.1890, 2.8458, 2.8149, 3.0512,\n",
      "        3.4695, 3.2619, 2.7119, 3.1999, 2.7209, 2.9357, 3.0625, 3.3887, 2.6983,\n",
      "        2.4580, 2.4210, 2.6398, 3.2214, 2.6077, 3.3068, 2.7447, 3.1589, 3.3864,\n",
      "        2.8613, 3.2562, 1.4391, 3.1539, 3.0611, 2.3995, 1.9673, 3.1959, 3.2844,\n",
      "        2.8847, 2.8684, 3.0708, 3.1371, 2.6611, 3.0987, 3.1981, 2.8259, 2.1071,\n",
      "        2.6231, 3.0663, 2.9794, 2.9240, 2.5405, 2.4813, 2.8115, 2.8899, 3.3546,\n",
      "        3.0986, 2.5009, 2.8207, 3.2461, 3.1382, 3.1578, 3.2135, 3.2250, 2.9199,\n",
      "        2.8787, 2.9645, 3.1286, 3.2356, 2.9585, 3.2216, 3.1924, 3.1764, 3.0291,\n",
      "        3.3572, 3.1134, 3.0492, 2.8910, 2.3146, 2.0567, 3.2019, 3.2652, 2.7047,\n",
      "        2.8584, 2.9963, 3.5136, 2.8984, 3.3339, 2.6576, 3.2072, 2.8780, 3.1798,\n",
      "        3.1697, 2.9350, 2.8784, 2.9795, 1.3575, 2.6200, 2.4510, 2.4649, 2.9905,\n",
      "        3.0370, 2.8259, 2.7835, 2.7889, 2.1759, 2.9952, 3.1958, 3.0589, 3.1452,\n",
      "        3.1596, 2.9518, 2.8490, 1.7442, 2.5620, 3.3748, 3.2189, 3.2189, 3.0811,\n",
      "        3.3373, 3.2046, 2.7436, 3.0748, 2.5197, 2.9479, 3.1901, 3.0052, 2.6981,\n",
      "        3.3230, 3.1839, 2.9298, 3.0787, 2.5551, 2.9952, 3.0881, 2.6518, 3.3033,\n",
      "        2.6815, 3.1511, 3.0181, 3.2122, 2.3548, 3.1208, 3.2125, 2.8780, 2.9897,\n",
      "        3.1186, 3.3585, 3.1923, 3.3253, 2.8023, 3.3486, 2.3318, 2.8839, 1.7521,\n",
      "        2.7778, 2.6606, 2.1189, 3.1610, 2.5840, 3.0644, 3.2338, 2.5308, 3.1559,\n",
      "        3.2024, 2.7359, 2.2085, 3.0432, 3.3923, 3.1364, 2.3397, 1.7382, 3.2837,\n",
      "        2.4496, 3.2575, 2.9730, 3.3552, 2.8194, 2.9351, 2.8632, 2.4321, 2.9596,\n",
      "        2.9458, 2.9227, 2.2997, 3.1660, 3.1534, 3.1683, 2.5599, 2.3120, 2.8915,\n",
      "        3.0626, 2.8428, 3.1129, 3.0802, 2.5481, 3.1590, 3.1967, 3.2550, 3.2275,\n",
      "        2.5060, 3.1227, 2.7483, 3.3407, 2.3992, 3.0091, 2.8069, 2.9019, 3.0765,\n",
      "        2.9819, 3.4136, 3.1576, 2.6436, 2.4997, 2.9756, 1.7688, 3.2164, 2.9010,\n",
      "        2.4538, 2.8013, 3.0399, 2.8669, 3.0045, 2.6093, 3.0475, 2.5024, 3.1447,\n",
      "        2.9815, 2.7051, 3.1912, 2.7503, 2.7619, 3.1295, 3.1689, 3.3018, 3.1891,\n",
      "        3.0559, 2.6309, 2.9720, 2.8274, 2.6982, 3.2152, 3.2864, 2.7494, 2.7623,\n",
      "        3.2028, 2.8754, 2.8188, 2.8562, 2.7432, 3.2238, 3.0750, 3.2401, 2.9338,\n",
      "        2.9635, 2.6890, 2.8470, 2.9237, 3.1196, 3.1540, 3.0380, 2.8618, 3.0767,\n",
      "        2.9874, 3.1763, 2.9445, 2.7867, 2.6891, 2.8796, 3.1123, 2.9992, 3.1111,\n",
      "        3.2862, 2.9356, 2.3572, 3.0545, 2.6427, 2.2858, 3.1156, 2.8751, 3.2337,\n",
      "        2.8752, 2.8316, 3.0464, 2.8375, 2.8192, 2.3709, 3.0614, 2.9339, 3.1204,\n",
      "        3.1630, 3.0415, 2.7278, 3.1454, 2.9601, 2.7550, 3.0481, 2.8338, 2.3922,\n",
      "        3.3607, 1.8972, 2.9697, 3.1837, 2.6109, 3.0791, 2.9670, 3.1476, 3.1914,\n",
      "        2.8314, 2.7825, 3.0322, 3.2094, 2.9745, 3.0163, 3.1789, 3.1096, 2.8107,\n",
      "        2.7327, 3.2264, 2.5724, 2.3837, 3.2496, 3.0875, 3.0738, 2.3977, 3.0271,\n",
      "        2.7531, 3.1663, 3.0210, 2.9254, 3.1594, 3.1633, 2.8221, 2.9318, 3.4469,\n",
      "        3.1913, 2.8918, 2.9919, 2.6659, 3.1626, 3.3280, 3.0682, 2.5204, 3.2086,\n",
      "        1.9499, 3.0288, 2.1335, 3.0142, 3.1433, 2.8908, 2.9473, 2.8180, 2.6559,\n",
      "        3.0207, 2.9227, 2.8593, 2.6532, 2.8542, 2.7625, 2.1959, 2.4141, 3.2937,\n",
      "        3.1108, 3.1079, 2.9567, 3.1018, 3.2180, 2.9590, 3.0006, 3.2810, 3.2728,\n",
      "        2.8985, 3.3129, 2.6433, 2.8221, 2.7783, 2.9007, 2.6125, 3.1806, 3.1862,\n",
      "        3.2794, 3.3860, 2.8180, 2.9694, 2.0663, 3.1131, 3.1569, 2.6813, 2.6054,\n",
      "        3.0380, 2.8783, 2.9010, 1.2009, 2.7526, 3.2109, 3.1728, 2.9744, 2.9515,\n",
      "        3.1801, 3.1934, 3.3369, 3.0410, 2.7910, 3.2037, 3.0834, 2.6740, 3.1165,\n",
      "        2.9314, 3.0267, 2.1463, 3.3202, 3.0531, 3.2692, 2.7618, 2.3479, 3.3503,\n",
      "        2.6739, 2.9915, 3.0149, 3.2050, 3.1287, 3.0329, 3.3506, 3.1644, 3.2490,\n",
      "        2.5068, 3.2572, 2.7148, 2.8105, 3.0899, 3.3021, 2.7630, 3.0665, 3.2685,\n",
      "        2.0122, 3.1686, 3.0711, 3.0269, 2.3319, 3.0174, 3.0314, 2.9877, 3.0465,\n",
      "        3.0587, 2.7144, 3.1859, 2.8139, 2.4878, 2.5209, 3.1654, 2.9942, 2.6738,\n",
      "        2.8239, 2.7699, 3.0676, 2.4111, 3.2794, 3.4435, 2.8068, 3.0014, 2.9927,\n",
      "        3.1337, 2.1270, 3.2333, 2.8322, 2.8705, 3.2840, 2.4579, 2.9993, 2.6779,\n",
      "        2.8853, 3.1095, 3.0499, 3.0354, 3.1500, 3.4002, 2.5479, 2.9663, 2.7910,\n",
      "        3.1559, 2.9422, 2.8010, 3.1570, 3.0749, 2.5917, 2.7376, 3.2468, 2.4247,\n",
      "        2.1337, 1.6384, 3.2258, 2.7170, 2.3313, 3.0537, 2.8208, 3.1810, 2.9630,\n",
      "        3.1328, 2.6801, 3.0147, 3.0345, 2.9359, 2.2744, 3.2712, 2.6799, 2.7453,\n",
      "        3.0278])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = torch.rand(test_samples,4).to(device)*10\n",
    "with torch.no_grad():\n",
    "    Y_pred = m4(X_test)\n",
    "    LHS=list()\n",
    "    RHS=list()\n",
    "    for t in range(test_samples):\n",
    "        LHS.append(torch.log(torch.sum(X_test[t])))\n",
    "        RHS.append(torch.sum(torch.log(X_test[t])*Y_pred[t][:-1]) + Y_pred[t][-1])\n",
    "    LHS=torch.tensor(LHS)\n",
    "    RHS=torch.tensor(RHS)\n",
    "    print(LHS)\n",
    "    print(RHS)\n",
    "    #plt.plot(X_test.numpy(), LHS.numpy(),color='r',label='LHS')\n",
    "    #plt.plot(X_test.numpy(), RHS.numpy(),color='r',label='LHS')\n",
    "    plt.scatter(LHS.numpy(),RHS.numpy())\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.jit.script(m4).save('m4.pt')\n",
    "torch.jit.script(m8).save('m8.pt')\n",
    "torch.jit.script(m16).save('m16.pt')\n",
    "torch.jit.script(m32).save('m32.pt')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}